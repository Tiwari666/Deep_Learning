# Deep_Learning

Artificial Intelligence: a program that can sense, reason, act and adapt.

Machine Learning: algorithms whose performance improve as they are exposed to more data over time.

Deep Learning: subset of machine learning in which multilayered neural networks learn from vast amounts of data.



# Difference between ML and DL

Machine learning consists of thousands of data points while deep learning uses millions of data points. Machine learning
algorithms usually perform well with relatively small datasets.

Deep Learning requires large amounts of data to understand and perform better than traditional machine learning algorithms.
Machine learning algorithms solve problems by using explicit programming. Deep learning algorithms solve problems based on
the layers of neural networks.

Machine learning algorithms take relatively less time to train, ranging from a few seconds to a few hours. Deep learning
algorithms, on the other hand, take a lot of time to train, ranging from a few hours to many weeks.

Conclusion:

In traditional Machine learning techniques, most of the applied features need to be identified by an domain expert in order to
reduce the complexity of the data and make patterns more visible to learning algorithms to work.

However,the Deep Learning algorithms try to learn high-level features from data in an incremental manner. This eliminates the
need of domain expertise and hard core feature extraction.
So, there is less intervention of human beings in the DL than in the ML.





![image](https://github.com/Tiwari666/Deep_Learning/assets/153152895/a37c2289-d507-4c26-88ca-a7c08385b268)



![image](https://github.com/Tiwari666/Deep_Learning/assets/153152895/d47e57d3-ab27-47d0-8490-95f0ee2b2510)



![image](https://github.com/Tiwari666/Deep_Learning/assets/153152895/43bc78a2-4b2f-4bf6-8948-09ccdcb04368)



![image](https://github.com/Tiwari666/Deep_Learning/assets/153152895/9ca7d22c-66df-4333-bf7c-54db986f7a0c)

Deep learning models tend to increase their accuracy with the increasing amount of training data, whereas traditional machine learning models such as SVM and naive Bayes classifier stop improving after a saturation point.




# Difference between ML and DL

ML involves training algorithms on large datasets to identify patterns and relationships and then using these patterns to make
predictions or decisions about new data.

DL is a subset of machine learning that uses neural networks with multiple layers to analyze complex patterns and relationships
in data. It is inspired by the structure and function of the human brain and has been successful in a variety of tasks, such as
computer vision, natural language processing, and speech recognition.

# What is a neural network?

Neural networks, also called artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine
learning and are the backbone of deep learning algorithms. They are called “neural” because they mimic how neurons in the
brain signal one another.
Neural networks are made up of node layers – an input layer, one or more hidden layers, and an output layer. Each node is an
artificial neuron that connects to the next, and each has a weight and threshold value. When one node’s output is above the
threshold value, that node is activated and sends its data to the network’s next layer. If it’s below the threshold, no data passes
along.
Training data teach neural networks and help improve their accuracy over time.




# Difference between deep learning and deep reinforcement learning:

While deep learning learns from real-world data, reinforcement learning learns from synthetic data as an agent interacts with an
environment, receiving feedback based on its actions.

Synthetic data is information that’s artificially manufactured rather than generated by real-world events. It’s created
algorithmically and is used as a stand-in for test data sets of production or operational data, to validate mathematical models
and to train machine learning (ML) models.


# Top 10 Deep Learning Techniques/Algorithms

1)  Classic Neural Networks

A) Feedforward neural network (E.G., facial recognition algorithm using computer vision) 

Since the data moves only in 1 direction there is no backpropagation technique in this network.

B) Radial basis function neural networks

This kind of neural network have generally more than 1 layer preferably two layers
In this kind of network, the relative distance from any point to the center is calculated and the same is passed towards the next layer
Radial basis networks are generally used in power restoration systems to restore the power in the shortest span of time to avoid blackouts.

C) Multi-layer perceptron:

This type of network are having more than 3 layers and its used to classify the data which is not linear
These kinds of networks are fully connected with every node.
These networks are extensively used for speech recognition and other machine learning technologies.

2) Convolutional Neural Networks

3) Recurrent Neural Networks (LSTM, Gated RNNs)

4) Transfer Learning

5) Restricted Boltzmann Machines

6) Generative Adversarial Networks

7) Deep Reinforcement Learning

8) Self-Organizing Maps

9) Autoencoders

10) Backpropagation



# Four pillars of deep learning:


A neural network is a computational model inspired by the structure and functioning of the human brain. It is a fundamental
component of machine learning and artificial intelligence. Neural networks consist of interconnected nodes, called neurons,
organized into layers. The three main types of layers in a neural network are the input layer, hidden layers, and output layer.

Here are the key components and concepts associated with neural networks:

1. Neurons:
Neurons are basic units in a neural network, analogous to the neurons in
the human brain.
Each neuron receives input, processes it using a weighted sum, applies an
activation function, and produces an output.

 
2. Layers:

Neural networks are organized into layers. The three primary types of
layers are:
Input Layer: This layer receives the initial input features.
Hidden Layers: These layers process the input through a series of weighted
connections and apply activation functions to produce complex
representations of the input.
Output Layer: The final layer produces the network’s output. 
 
4. Weights and Biases:

The connections between neurons are represented by weights. Each
connection has an associated weight that determines the strength of the
connection.

Biases are additional parameters added to each neuron that allow the
network to learn transformations that don’t pass through the origin.

5. Activation Functions:
Activation functions introduce non-linearity to the model, enabling it to
learn complex relationships in the data.
Common activation functions include sigmoid, hyperbolic tangent (tanh),
and rectified linear unit (ReLU).

6. Feedforward and Backpropagation:

In the training phase, data is fed forward through the network to produce
predictions.
Backpropagation is used to update the weights and biases of the network
based on the difference between the predicted output and the actual
target, minimizing the error
    
7. Loss Function:

The loss function measures the difference between the predicted output
and the true target. The goal during training is to minimize this loss.


 
8. Optimization Algorithms (e.g., gradient descent)
Optimization algorithms, such as gradient descent, are used to adjust the
weights and biases iteratively during training to minimize the loss.



Neural networks can be applied to various tasks, including image and speech recognition, natural language processing, and
regression. Deep learning refers to the use of neural networks with multiple hidden layers, often referred to as deep neural
networks. The depth and complexity of neural networks allow them to learn hierarchical and abstract features from data, making
them powerful tools for a wide range of applications.



  
  
# REFERENCES:

LINK1: https://builtin.com/artificial-intelligence/ai-vs-machine-learning

Link2: https://www.linkedin.com/pulse/what-deep-learning-definition-techniques-examples-neil-sahota

Link 3: Various Online sources

Link4: https://www.educba.com/deep-learning-networks/
